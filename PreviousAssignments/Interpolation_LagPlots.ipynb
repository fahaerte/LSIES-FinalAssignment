{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from geopy import distance\n",
    "from csv import reader\n",
    "from sklearn.metrics import r2_score\n",
    "from datetime import datetime\n",
    "from datetime import timedelta as tdelta\n",
    "from datetime import time as time\n",
    "from helpe_funcs import *\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Data import ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### I.a) Import positions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_name = 'sensor_positions.csv'\n",
    "coords = []\n",
    "IDs = []\n",
    "\n",
    "with open('./data/' + csv_file_name, 'r') as read_obj:\n",
    "    csv_reader = reader(read_obj)\n",
    "    for row in csv_reader:\n",
    "        coord = (float(row[0].split(' ')[0].replace('(', '')), \n",
    "                 float(row[0].split(' ')[1].replace(')', '')) )\n",
    "        coords.append(coord)\n",
    "        \n",
    "        IDs.append(row[1])\n",
    "\n",
    "stations_df = pd.DataFrame(data={'coords': coords, 'IDs': IDs})\n",
    "stations_df.drop_duplicates(subset='IDs', keep='first', inplace=True)\n",
    "stations_df.set_index('IDs', inplace=True)\n",
    "\n",
    "IDs = list(stations_df.index)\n",
    "\n",
    "del csv_file_name, coords, csv_reader, read_obj, row"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.b) Form groups based on distance between stations ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = make_groups(IDs, stations_df)\n",
    "stations_df.insert(loc=1, column='grps', value=groups['grp'])\n",
    "\n",
    "del groups"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.c) Import sound pressure values ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dir_path = './data'\n",
    "csv_file_names = []\n",
    "\n",
    "for path in os.listdir(dir_path):\n",
    "    if os.path.isfile(os.path.join(dir_path, path)):\n",
    "        if path.find('data.csv') != -1:\n",
    "            csv_file_names.append(path)\n",
    "            \n",
    "del path, dir_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Append all csv files to a list of dataframes and add the id of the sensor to distinguish them later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "list_df = []\n",
    "sensor_names = []\n",
    "\n",
    "\n",
    "for filename in csv_file_names:\n",
    "    df = pd.read_csv('./data/' + filename, index_col=None, header=0)\n",
    "    df['Time'] = df.apply(lambda row: datetime.strptime(row['Time'], '%Y-%m-%d %H:%M:%S'), axis=1)\n",
    "    sensor_names.append(filename[12:16]);\n",
    "    list_df.append(df);\n",
    "\n",
    "list_len = [len(df) for df in list_df];\n",
    "\n",
    "del filename, csv_file_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.d) Get rid of duplicates and fill in missing timestamps ###\n",
    "-> data is transformed into uniformely sampled data with `np.nan()` in place of missing values\n",
    "-> start date is 2022.02.20 00:00:00, stop date is 2022.03.05 00:00:00\n",
    "-> all data is organised into a DataFrame, columns=Sensor IDs, index=Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.strptime('2022.02.20 00:00:00', '%Y.%m.%d %H:%M:%S')\n",
    "end_time = datetime.strptime('2022.03.05 00:00:00', '%Y.%m.%d %H:%M:%S')\n",
    "tindex = pd.date_range(start_time, end_time, freq='1min')\n",
    "data_label='dt_sound_level_dB'\n",
    "\n",
    "df_data_incomplete = pd.DataFrame(index=tindex, columns=sensor_names)\n",
    "\n",
    "list_df_incomplete = []\n",
    "\n",
    "idx = 0\n",
    "for df in list_df:\n",
    "    # get rid of redundant datapoints\n",
    "    df = df[df.Time >= start_time]\n",
    "    df = df[df.Time <= end_time]\n",
    "    df.drop_duplicates(subset='Time', keep='first', inplace=True)\n",
    "    \n",
    "    # index data by Time\n",
    "    df.index = pd.to_datetime(df['Time'])\n",
    "    df.drop(columns=['Time'], inplace=True)\n",
    "    df = df.reindex(tindex)\n",
    "    \n",
    "    list_df_incomplete.append(df)\n",
    "    df_data_incomplete[sensor_names[idx]] = df[data_label]\n",
    "    idx = idx + 1\n",
    "\n",
    "del df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## II. Interpolation ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.a) Simple interpolation ###\n",
    "-> 'nearest'\n",
    "-> 'linear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#interpolate data using 'nearest' method\n",
    "list_df_other = []\n",
    "list_df_linear = []\n",
    "list_df_nearest = []\n",
    "\n",
    "\n",
    "for df in list_df_incomplete:\n",
    "    temp_df = df.interpolate(method='nearest')\n",
    "    temp_df = temp_df.interpolate(limit_area=None, method='backfill')  \n",
    "    df['int_nearest'] = temp_df['dt_sound_level_dB']\n",
    "    list_df_nearest.append(temp_df)\n",
    "    \n",
    "for df in list_df_incomplete:\n",
    "    temp_df = df.interpolate(method='linear')\n",
    "    # linear not possible backwards -> backfill\n",
    "    temp_df = temp_df.interpolate(limit_area=None, method='backfill') \n",
    "    df['int_linear'] = temp_df['dt_sound_level_dB']\n",
    "    df.apply(lambda x: np.round(x['int_linear'], 1), 1)\n",
    "    list_df_linear.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = []\n",
    "\n",
    "for id in sensor_names:\n",
    "    # 1) extract data from \"friends\"\n",
    "    group = stations_df.loc[id]['grps']\n",
    "    group_df = data_df.loc[group]['incomplete']\n",
    "    single_df = data_df.loc[id]['incomplete']\n",
    "    for fid in group[1:len-2]:\n",
    "        corrs.append(calculate_correlations(single_df, group_df[fid]))\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.b) Attempts on advanced interpolation ###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.b.1) Raw data separation and filtering ####\n",
    "-> data is separated into 2 groups: workdays(`df_work_...`), weekenddays(`df_end_...`)\n",
    "-> data is further filtered (meaned) to create average workday and average weekend day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_str = datetime.strptime('2023.05.01 00:00:00', '%Y.%m.%d %H:%M:%S')\n",
    "day_stp = datetime.strptime('2023.05.01 23:59:59', '%Y.%m.%d %H:%M:%S')\n",
    "daindex = pd.date_range(day_str, day_stp, freq='1min')\n",
    "\n",
    "df_work_mean = pd.DataFrame(index=daindex, columns=sensor_names)\n",
    "df_end_mean = pd.DataFrame(index=daindex, columns=sensor_names)\n",
    "\n",
    "df_work_all = df_data_incomplete.loc[df_data_incomplete.index.day_of_week < 5].copy()\n",
    "df_end_all = df_data_incomplete.loc[df_data_incomplete.index.day_of_week > 4].copy()\n",
    "\n",
    "df_mean_ww = df_work_all.copy()\n",
    "df_mean_we = df_end_all.copy()\n",
    "\n",
    "for moment in daindex:\n",
    "    idxs_work = df_work_all.index.indexer_at_time(moment.time())\n",
    "    idxs_end = df_end_all.index.indexer_at_time(moment.time())\n",
    "    \n",
    "    df_work_mean.loc[moment] = df_work_all.iloc[idxs_work].mean()\n",
    "    df_end_mean.loc[moment] = df_end_all.iloc[idxs_end].mean()\n",
    "    \n",
    "    df_mean_ww.iloc[idxs_work] = df_work_mean.loc[moment]\n",
    "    df_mean_we.iloc[idxs_end] = df_end_mean.loc[moment]\n",
    "    \n",
    "df_mean = pd.concat([df_mean_we, df_mean_ww], axis=0)\n",
    "df_mean.sort_index(inplace=True)\n",
    "\n",
    "del day_stp, day_str\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.b.2) Determine resampling period ####\n",
    "\n",
    "Determine resampling period based on rmse=f(Tresample)\n",
    "\n",
    "1) for mean interpolation\n",
    "2) for linear interpolation\n",
    "\n",
    "The data is downsampled for sampling periods of [1, 2, 5, 10, 15, 20, 30, 60] minutes and rmse is calculated to provide an esimate for information loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) mean interpolation - simple resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_pers = [1, 2, 5, 10, 15, 20, 30, 60]\n",
    "\n",
    "list_rmses = []\n",
    "    \n",
    "resample_vars_d = pd.DataFrame(data=np.zeros([len(sensor_names), len(resample_pers)]), columns=resample_pers, index=sensor_names)\n",
    "resample_vars_e = resample_vars_d.copy()\n",
    "resample_vars_n = resample_vars_d.copy()\n",
    "\n",
    "df_resvar_d = df_data_incomplete.iloc[indexer_day(df_data_incomplete)]\n",
    "df_resvar_e = df_data_incomplete.iloc[indexer_evening(df_data_incomplete)]\n",
    "df_resvar_n = df_data_incomplete.iloc[indexer_night(df_data_incomplete)]\n",
    "\n",
    "for per in resample_pers:\n",
    "    resample_vars_d[per] = df_resvar_d.resample(str(per)+'T').rmse().mean()\n",
    "    resample_vars_e[per] = df_resvar_e.resample(str(per)+'T').rmse().mean()\n",
    "    resample_vars_n[per] = df_resvar_n.resample(str(per)+'T').rmse().mean()\n",
    " \n",
    "resample_vars_d[1]=np.zeros(len(sensor_names)) \n",
    "resample_vars_n[1]=np.zeros(len(sensor_names)) \n",
    "resample_vars_e[1]=np.zeros(len(sensor_names))  \n",
    "\n",
    "list_rmses.append([resample_vars_d.mean(),\n",
    "                   resample_vars_e.mean(),\n",
    "                   resample_vars_n.mean()])\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax = init_ax_resamp(ax, resample_pers, )\n",
    "plt.show()  \n",
    "\n",
    "del  resample_vars_d, resample_vars_n, resample_vars_e, resample_pers\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) mean interpolation - average days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig_d = df_data_incomplete.iloc[indexer_day(df_data_incomplete)]\n",
    "df_orig_e = df_data_incomplete.iloc[indexer_evening(df_data_incomplete)]\n",
    "df_orig_n = df_data_incomplete.iloc[indexer_night(df_data_incomplete)]\n",
    "\n",
    "df_mean_d = df_mean.iloc[indexer_day(df_mean)]\n",
    "df_mean_e = df_mean.iloc[indexer_evening(df_mean)]\n",
    "df_mean_n = df_mean.iloc[indexer_night(df_mean)]\n",
    "\n",
    "df_resamp_d = pd.DataFrame()\n",
    "df_resamp_e = pd.DataFrame()\n",
    "df_resamp_n = pd.DataFrame()\n",
    "\n",
    "for per in resample_pers:\n",
    "    df_mean_d[per] = df_mean_d.resample(str(per)+'T').mean()\n",
    "    df_mean_e[per] = df_mean_e.resample(str(per)+'T').mean()\n",
    "    df_mean_n[per] = df_mean_n.resample(str(per)+'T').mean()\n",
    " \n",
    "resample_vars_d[1]=np.zeros(len(sensor_names)) \n",
    "resample_vars_n[1]=np.zeros(len(sensor_names)) \n",
    "resample_vars_e[1]=np.zeros(len(sensor_names))  \n",
    "\n",
    "list_rmses.append([resample_vars_d.mean(),\n",
    "                   resample_vars_e.mean(),\n",
    "                   resample_vars_n.mean()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TESTING #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "MergeError",
     "evalue": "Can not pass on, right_on, left_on or set right_index=True or left_index=True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test \u001b[39m=\u001b[39m df_mean_ww\u001b[39m.\u001b[39;49mmerge(df_mean_we, how\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcross\u001b[39;49m\u001b[39m'\u001b[39;49m, left_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, right_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:9843\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m   9824\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   9825\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m   9826\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9839\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   9840\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m   9841\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmerge\u001b[39;00m \u001b[39mimport\u001b[39;00m merge\n\u001b[1;32m-> 9843\u001b[0m     \u001b[39mreturn\u001b[39;00m merge(\n\u001b[0;32m   9844\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   9845\u001b[0m         right,\n\u001b[0;32m   9846\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[0;32m   9847\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[0;32m   9848\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[0;32m   9849\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[0;32m   9850\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[0;32m   9851\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[0;32m   9852\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m   9853\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[0;32m   9854\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   9855\u001b[0m         indicator\u001b[39m=\u001b[39;49mindicator,\n\u001b[0;32m   9856\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m   9857\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\merge.py:142\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    126\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    141\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m--> 142\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[0;32m    143\u001b[0m         left,\n\u001b[0;32m    144\u001b[0m         right,\n\u001b[0;32m    145\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[0;32m    146\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[0;32m    147\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[0;32m    148\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[0;32m    149\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[0;32m    150\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[0;32m    151\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    152\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[0;32m    153\u001b[0m         indicator\u001b[39m=\u001b[39;49mindicator,\n\u001b[0;32m    154\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m    155\u001b[0m     )\n\u001b[0;32m    156\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result(copy\u001b[39m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\merge.py:713\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    706\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[0;32m    707\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNot allowed to merge between different levels. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    708\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m_left\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels\u001b[39m}\u001b[39;00m\u001b[39m levels on the left, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    709\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m_right\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels\u001b[39m}\u001b[39;00m\u001b[39m on the right)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    710\u001b[0m     )\n\u001b[0;32m    711\u001b[0m     \u001b[39mraise\u001b[39;00m MergeError(msg)\n\u001b[1;32m--> 713\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft_on, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_on \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_left_right_on(left_on, right_on)\n\u001b[0;32m    715\u001b[0m cross_col \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhow \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcross\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\merge.py:1462\u001b[0m, in \u001b[0;36m_MergeOperation._validate_left_right_on\u001b[1;34m(self, left_on, right_on)\u001b[0m\n\u001b[0;32m   1454\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhow \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcross\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1455\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1456\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft_index\n\u001b[0;32m   1457\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_index\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1460\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1461\u001b[0m     ):\n\u001b[1;32m-> 1462\u001b[0m         \u001b[39mraise\u001b[39;00m MergeError(\n\u001b[0;32m   1463\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCan not pass on, right_on, left_on or set right_index=True or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1464\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mleft_index=True\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1465\u001b[0m         )\n\u001b[0;32m   1466\u001b[0m \u001b[39m# Hm, any way to make this logic less complicated??\u001b[39;00m\n\u001b[0;32m   1467\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m left_on \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m right_on \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mMergeError\u001b[0m: Can not pass on, right_on, left_on or set right_index=True or left_index=True"
     ]
    }
   ],
   "source": [
    "test = df_mean_ww.merge(df_mean_we, how='cross', left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for df in [ensemble1, ensemble2]:\n",
    "    mean_list = []\n",
    "    median_list = []\n",
    "    std_list = []\n",
    "\n",
    "    for size in sample_sizes:\n",
    "        sample_size = int(size * len(df))\n",
    "        sample = df.sample(n=sample_size, replace=False)\n",
    "        mean_list.append(np.mean(sample['mean']))\n",
    "        median_list.append(np.median(sample['mean']))\n",
    "        std_list.append(np.std(sample['mean']))\n",
    "\n",
    "    means.append(mean_list)\n",
    "    medians.append(median_list)\n",
    "    stds.append(std_list)\n",
    "\n",
    "fig, ax = plt.subplots(3, figsize=(10, 10))\n",
    "\n",
    "for axis in range(3):\n",
    "    for i, name in enumerate(['ensemble1', 'ensemble2']):\n",
    "        ax[axis].plot(sample_sizes, stat_data[axis][i], label=name)\n",
    "\n",
    "    ax[axis].set_title(stats[axis])\n",
    "    ax[axis].set_xlabel('sample percentage')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
