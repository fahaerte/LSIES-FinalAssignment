{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from csv import reader\n",
    "from sklearn.metrics import r2_score\n",
    "from datetime import datetime\n",
    "from datetime import timedelta as tdelta\n",
    "from datetime import time as time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpe_funcs import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Data import ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### I.a) Import positions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_name = 'sensor_positions.csv'\n",
    "coords = []\n",
    "IDs = []\n",
    "\n",
    "with open('./data/' + csv_file_name, 'r') as read_obj:\n",
    "    csv_reader = reader(read_obj)\n",
    "    for row in csv_reader:\n",
    "        coord = (float(row[0].split(' ')[0].replace('(', '')), \n",
    "                 float(row[0].split(' ')[1].replace(')', '')) )\n",
    "        coords.append(coord)\n",
    "        \n",
    "        IDs.append(row[1])\n",
    "\n",
    "stations_df = pd.DataFrame(data={'coords': coords, 'IDs': IDs})\n",
    "stations_df.drop_duplicates(subset='IDs', keep='first', inplace=True)\n",
    "stations_df.set_index('IDs', inplace=True)\n",
    "\n",
    "IDs = list(stations_df.index)\n",
    "\n",
    "del csv_file_name, coords, csv_reader, read_obj, row"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.b) Form groups based on distance between stations ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create groups of sensors based on distance between them\n"
     ]
    }
   ],
   "source": [
    "groups = make_groups(IDs, stations_df)\n",
    "stations_df.insert(loc=1, column='grps', value=groups['grp'])\n",
    "\n",
    "del groups"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.c) Import sound pressure values ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dir_path = './data'\n",
    "csv_file_names = []\n",
    "\n",
    "for path in os.listdir(dir_path):\n",
    "    if os.path.isfile(os.path.join(dir_path, path)):\n",
    "        if path.find('data.csv') != -1:\n",
    "            csv_file_names.append(path)\n",
    "            \n",
    "del path, dir_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Append all csv files to a list of dataframes and add the id of the sensor to distinguish them later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "list_df = []\n",
    "sensor_names = []\n",
    "\n",
    "\n",
    "for filename in csv_file_names:\n",
    "    df = pd.read_csv('./data/' + filename, index_col=None, header=0)\n",
    "    df['Time'] = df.apply(lambda row: datetime.strptime(row['Time'], '%Y-%m-%d %H:%M:%S'), axis=1)\n",
    "    sensor_names.append(filename[12:16]);\n",
    "    list_df.append(df);\n",
    "\n",
    "list_len = [len(df) for df in list_df];\n",
    "\n",
    "del filename, csv_file_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.d) Get rid of duplicates and fill in missing timestamps ###\n",
    "-> data is transformed into uniformely sampled data with `np.nan()` in place of missing values\n",
    "-> start date is 2022.02.20 00:00:00, stop date is 2022.03.05 00:00:00\n",
    "-> all data is organised into a DataFrame, columns=Sensor IDs, index=Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.strptime('2022.02.20 00:00:00', '%Y.%m.%d %H:%M:%S')\n",
    "end_time = datetime.strptime('2022.03.05 00:00:00', '%Y.%m.%d %H:%M:%S')\n",
    "tindex = pd.date_range(start_time, end_time, freq='1min')\n",
    "data_label='dt_sound_level_dB'\n",
    "\n",
    "df_data_incomplete = pd.DataFrame(index=tindex, columns=sensor_names)\n",
    "\n",
    "list_df_incomplete = []\n",
    "\n",
    "idx = 0\n",
    "for df in list_df:\n",
    "    # get rid of redundant datapoints\n",
    "    df = df[df.Time >= start_time]\n",
    "    df = df[df.Time <= end_time]\n",
    "    df.drop_duplicates(subset='Time', keep='first', inplace=True)\n",
    "    \n",
    "    # index data by Time\n",
    "    df.index = pd.to_datetime(df['Time'])\n",
    "    df.drop(columns=['Time'], inplace=True)\n",
    "    df = df.reindex(tindex)\n",
    "    \n",
    "    list_df_incomplete.append(df)\n",
    "    df_data_incomplete[sensor_names[idx]] = df[data_label]\n",
    "    idx = idx + 1\n",
    "\n",
    "del df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## II. Interpolation ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.a) Simple interpolation ###\n",
    "-> 'nearest'\n",
    "-> 'linear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#interpolate data using 'nearest' method\n",
    "list_df_other = []\n",
    "list_df_linear = []\n",
    "list_df_nearest = []\n",
    "\n",
    "\n",
    "temp_df = df_data_incomplete.interpolate(method='nearest')\n",
    "df_data_nearest = temp_df.interpolate(limit_area=None, method='backfill')\n",
    "  \n",
    "temp_df = df_data_incomplete.interpolate(method='linear')\n",
    "df_data_linear = temp_df.interpolate(limit_area=None, method='backfill') \n",
    "df_data_linear.apply(lambda x: np.round(x, 1), 1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.b) Attempts on advanced interpolation ###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.b.1) Raw data separation and filtering ####\n",
    "-> data is separated into 2 groups: workdays(`df_work_...`), weekenddays(`df_end_...`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_str = datetime.strptime('2023.05.01 00:00:00', '%Y.%m.%d %H:%M:%S')\n",
    "day_stp = datetime.strptime('2023.05.01 23:59:59', '%Y.%m.%d %H:%M:%S')\n",
    "daindex = pd.date_range(day_str, day_stp, freq='1min')\n",
    "\n",
    "df_workd_mean = pd.DataFrame(index=daindex, columns=sensor_names)\n",
    "df_endd_mean = pd.DataFrame(index=daindex, columns=sensor_names)\n",
    "\n",
    "df_work_all = df_data_incomplete.loc[df_data_incomplete.index.day_of_week < 5].copy()\n",
    "df_end_all = df_data_incomplete.loc[df_data_incomplete.index.day_of_week > 4].copy()\n",
    "\n",
    "for moment in daindex:\n",
    "    idxs_work = df_work_all.index.indexer_at_time(moment.time())\n",
    "    idxs_end = df_end_all.index.indexer_at_time(moment.time())\n",
    "    \n",
    "    df_workd_mean.loc[moment] = df_work_all.iloc[idxs_work].mean()\n",
    "    df_endd_mean.loc[moment] = df_end_all.iloc[idxs_end].mean()\n",
    "\n",
    "del day_stp, day_str, idxs_work, idxs_end\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.b.2) Mean-day model interpolation ####\n",
    "-> data is filtered (meaned) to create average workday and average weekend day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_ww = df_work_all.copy()\n",
    "df_mean_we = df_end_all.copy()\n",
    "\n",
    "for moment in daindex:\n",
    "    idxs_work = df_work_all.index.indexer_at_time(moment.time())\n",
    "    idxs_end = df_end_all.index.indexer_at_time(moment.time())\n",
    "    \n",
    "    df_mean_ww.iloc[idxs_work] = df_workd_mean.loc[moment]\n",
    "    df_mean_we.iloc[idxs_end] = df_endd_mean.loc[moment]\n",
    "    \n",
    "df_mean = pd.concat([df_mean_we, df_mean_ww], axis=0)\n",
    "df_mean.sort_index(inplace=True)\n",
    "\n",
    "del df_mean_ww, df_mean_we"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.b.3) Neighbor data interpolation ####\n",
    "-> Missing data is filled with data of neighboring sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.b.4) Determine resampling period ####\n",
    "\n",
    "Determine resampling period based on rmse=f(Tresample)\n",
    "\n",
    "1) for mean interpolation\n",
    "2) for linear interpolation\n",
    "\n",
    "The data is downsampled for sampling periods of [1, 2, 5, 10, 15, 20, 30, 60] minutes and rmse is calculated to provide an esimate for information loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) no interpolation - simple resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_rmses = []\n",
    "resample_pers = [1, 2, 5, 10, 15, 20, 30, 60]\n",
    "fig, ax = plt.subplots(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_interpolation_res = evaluate_resample(df_data_incomplete, df_data_incomplete) \n",
    "\n",
    "list_rmses.append([no_interpolation_res[0].mean(),\n",
    "                   no_interpolation_res[1].mean(),\n",
    "                   no_interpolation_res[2].mean()])\n",
    "\n",
    "ax[0, 0] = init_ax_resamp(ax[0, 0], resample_pers, list_rmses)\n",
    "ax[0, 0].set_title('No interpolation,  only downsampling')    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) mean interpolation - average days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_interpolation_res = evaluate_resample(df_data_incomplete, df_mean)\n",
    " \n",
    "\n",
    "list_rmses.append([mean_interpolation_res[0].mean(),\n",
    "                   mean_interpolation_res[1].mean(),\n",
    "                   mean_interpolation_res[2].mean()])\n",
    "\n",
    "ax[0, 1] = init_ax_resamp(ax[0, 1], resample_pers, list_rmses)\n",
    "ax[0, 1].set_title('Mean day interpolation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax[1, 0] = init_ax_resamp(ax[1, 0], resample_pers, list_rmses)\n",
    "ax[1, 1] = init_ax_resamp(ax[1, 1], resample_pers, list_rmses)\n",
    "\n",
    "\n",
    "ax[1, 0].set_title('Region 3')\n",
    "ax[1, 1].set_title('Region 4')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = no_interpolation_res[0].copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TESTING #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test = df_mean_ww.merge(df_mean_we, how='cross', left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "corrs = []\n",
    "\n",
    "for id in sensor_names:\n",
    "    # 1) extract data from \"friends\"\n",
    "    group = stations_df.loc[id]['grps']\n",
    "    group_df = data_df.loc[group]['incomplete']\n",
    "    single_df = data_df.loc[id]['incomplete']\n",
    "    for fid in group[1:len-2]:\n",
    "        corrs.append(calculate_correlations(single_df, group_df[fid]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for df in [ensemble1, ensemble2]:\n",
    "    mean_list = []\n",
    "    median_list = []\n",
    "    std_list = []\n",
    "\n",
    "    for size in sample_sizes:\n",
    "        sample_size = int(size * len(df))\n",
    "        sample = df.sample(n=sample_size, replace=False)\n",
    "        mean_list.append(np.mean(sample['mean']))\n",
    "        median_list.append(np.median(sample['mean']))\n",
    "        std_list.append(np.std(sample['mean']))\n",
    "\n",
    "    means.append(mean_list)\n",
    "    medians.append(median_list)\n",
    "    stds.append(std_list)\n",
    "\n",
    "fig, ax = plt.subplots(3, figsize=(10, 10))\n",
    "\n",
    "for axis in range(3):\n",
    "    for i, name in enumerate(['ensemble1', 'ensemble2']):\n",
    "        ax[axis].plot(sample_sizes, stat_data[axis][i], label=name)\n",
    "\n",
    "    ax[axis].set_title(stats[axis])\n",
    "    ax[axis].set_xlabel('sample percentage')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
