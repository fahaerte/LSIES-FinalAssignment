{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Bonus Assignment - Fabian Härtel - 31.03.2023"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "(1) Import all csv files, without the meta data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dir_path = './data'\n",
    "csv_file_names = []\n",
    "\n",
    "for path in os.listdir(dir_path):\n",
    "    if os.path.isfile(os.path.join(dir_path, path)):\n",
    "        if path.find('.csv') != -1:\n",
    "            csv_file_names.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "(1) Append all csv files to a list of dataframes and add the id of the sensor to distinguish them later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "list_df = []\n",
    "sensor_names = []\n",
    "\n",
    "for filename in csv_file_names:\n",
    "    df = pd.read_csv('./data/' + filename, index_col=None, header=0)\n",
    "    df['Time'] = df.apply(lambda row: datetime.strptime(row['Time'], '%Y-%m-%d %H:%M:%S'), axis=1)\n",
    "\n",
    "    sensor_names.append(filename[12:16])\n",
    "    df.rename(columns={'dt_sound_level_dB': filename[12:16]}, inplace=True)\n",
    "    list_df.append(df)\n",
    "\n",
    "list_len = [len(df) for df in list_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "(1) Remove all measurements with a timestamp not inbetween 2022.02.20 00:00:00 to 2022.03.04 24:00:00, set the timestamp as index of the dataframe, and add the start and end timestamp of the measurement period to the dataframe it doesn’t exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_time = datetime.strptime('2022.02.20 00:00:00', '%Y.%m.%d %H:%M:%S')\n",
    "end_time = datetime.strptime('2022.03.05 00:00:00', '%Y.%m.%d %H:%M:%S')\n",
    "\n",
    "df_counter = 0\n",
    "\n",
    "for df in list_df:\n",
    "    df = df[df.Time >= start_time]\n",
    "    df = df[df.Time <= end_time]\n",
    "\n",
    "    start_row = pd.DataFrame({'Time': start_time, 'dt_sound_level_dB': df.iloc[0][sensor_names[df_counter]]}, index=[0])\n",
    "    start_row['Time'] = pd.to_datetime(start_row['Time'])\n",
    "\n",
    "    end_row = pd.DataFrame({'Time': end_time, sensor_names[df_counter]: df.iloc[-1][sensor_names[df_counter]]}, index=[0])\n",
    "    end_row['Time'] = pd.to_datetime(end_row['Time'])\n",
    "\n",
    "    df['Time'] = pd.to_datetime(df['Time'])\n",
    "    df = df.set_index('Time')\n",
    "\n",
    "    if not (df.index == end_time).any():\n",
    "        df.loc[end_time] = [df.iloc[-1][sensor_names[df_counter]]]\n",
    "\n",
    "    if not (df.index == start_time).any():\n",
    "        df.loc[start_time] = [df.iloc[0][sensor_names[df_counter]]]\n",
    "\n",
    "    df = df.sort_values(by='Time')\n",
    "    df_counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "(1) Convert the time series to equally-spaced data with one minute time intervals and interpolate missing data with the “nearest” interpolant. Therefore, let’s insert all missing timestamps first, join existing measurements and finally interpolate missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "dt = start_time\n",
    "step = datetime.timedelta(minutes=1)\n",
    "result = []\n",
    "\n",
    "while dt < end_time:\n",
    "    result.append(dt.strftime('%Y.%m.%d %H:%M:%S'))\n",
    "    dt += step\n",
    "\n",
    "col = {'Time': result, 'dummy': 0}\n",
    "df_all_timestamps = pd.DataFrame(data=col)\n",
    "df_all_timestamps['Time'] = pd.to_datetime(df_all_timestamps['Time'])\n",
    "df_all_timestamps = df_all_timestamps.set_index('Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "(1) Interpolate missing data and merge all stations into one dataframe (increase rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "list_df_inter = []\n",
    "df_counter = 0\n",
    "df_final = df_all_timestamps.drop('dummy', axis=1)\n",
    "for df in list_df:\n",
    "    df = df_all_timestamps.merge(df, how='left', on='Time')\n",
    "    df = df.drop('dummy', axis=1)\n",
    "    while df[sensor_names[df_counter]].isnull().values.any():\n",
    "        df = df.interpolate(method='bfill', limit=1)\n",
    "        df = df.interpolate(method='ffill', limit=1)\n",
    "    df = df.set_index('Time')\n",
    "    df = df.resample('1T').mean()\n",
    "    df_counter += 1\n",
    "    df_final = df_final.merge(df, how='left', on='Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "(2) Calculate the RMSE as a function of rank against the resampled data for each station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calc_SVD_RMSE(df):\n",
    "    U, s, Vt = np.linalg.svd(df)\n",
    "\n",
    "    rank_range = range(1, len(df.columns) + 1)\n",
    "    rmse_list = []\n",
    "    amount_sing_values = []\n",
    "\n",
    "    for rank in rank_range:\n",
    "        Sigma = np.zeros((df.shape[0], df.shape[1]))\n",
    "        Sigma[:rank, :rank] = np.diag(s[:rank])\n",
    "        df_recon = U.dot(Sigma.dot(Vt))\n",
    "\n",
    "        rmse = np.sqrt(np.mean((df - df_recon)**2))\n",
    "        rmse_list.append(rmse.mean())\n",
    "        amount_sing_values.append(Sigma[rank-1][rank-1])\n",
    "\n",
    "    return rmse_list, amount_sing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m df_final\u001B[38;5;241m.\u001B[39mreset_index(inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      2\u001B[0m df_without_timestamp \u001B[38;5;241m=\u001B[39m df_final\u001B[38;5;241m.\u001B[39miloc[:, \u001B[38;5;241m1\u001B[39m:\u001B[38;5;28mlen\u001B[39m(df_final\u001B[38;5;241m.\u001B[39mcolumns)\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m----> 4\u001B[0m rmse_list, amount_sing_values \u001B[38;5;241m=\u001B[39m \u001B[43mcalc_SVD_RMSE\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_without_timestamp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m rank \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(rmse_list)):\n\u001B[0;32m      7\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRank: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrank\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m RMSE: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrmse_list[rank]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Singular Values: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mamount_sing_values[rank]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn[8], line 11\u001B[0m, in \u001B[0;36mcalc_SVD_RMSE\u001B[1;34m(df)\u001B[0m\n\u001B[0;32m      9\u001B[0m Sigma \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((df\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], df\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]))\n\u001B[0;32m     10\u001B[0m Sigma[:rank, :rank] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdiag(s[:rank])\n\u001B[1;32m---> 11\u001B[0m df_recon \u001B[38;5;241m=\u001B[39m \u001B[43mU\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mSigma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mVt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m rmse \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msqrt(np\u001B[38;5;241m.\u001B[39mmean((df \u001B[38;5;241m-\u001B[39m df_recon)\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m))\n\u001B[0;32m     14\u001B[0m rmse_list\u001B[38;5;241m.\u001B[39mappend(rmse\u001B[38;5;241m.\u001B[39mmean())\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "df_final.reset_index(inplace=True)\n",
    "df_without_timestamp = df_final.iloc[:, 1:len(df_final.columns)+1]\n",
    "\n",
    "rmse_list, amount_sing_values = calc_SVD_RMSE(df_without_timestamp)\n",
    "\n",
    "for rank in range(len(rmse_list)):\n",
    "        print(f'Rank: {rank+1} RMSE: {rmse_list[rank]} Singular Values: {amount_sing_values[rank]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "(3) Calculate the ensemble average SPL and substract it from each individual station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_without_timestamp_sub = df_without_timestamp.sub(df_without_timestamp.mean(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "(3) Rerun steps 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rmse_list_sub, amount_sing_values_sub = calc_SVD_RMSE(df_without_timestamp_sub)\n",
    "\n",
    "for rank in range(len(rmse_list_sub)):\n",
    "    print(f'Rank: {rank+1} RMSE: {rmse_list[rank]} Singular Values: {amount_sing_values_sub[rank]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Lower the Singular values of Rank 1 to being able to plot a better graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "amount_sing_values[0] = amount_sing_values[0] / 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "(4) Plot the singular values and the RMSE (dual y-axes) versus the rank (x-axis) for all stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rank_range = range(1, len(df_final.columns))\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "colory1 = 'tab:red'\n",
    "ax1.set_xlabel('Rank')\n",
    "ax1.set_ylabel('Singular Values', color=colory1)\n",
    "ax1.plot(rank_range, amount_sing_values, color=colory1)\n",
    "ax1.plot(rank_range, amount_sing_values_sub, color=colory1)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "colory2 = 'tab:blue'\n",
    "ax2.set_ylabel('RMSE', color=colory2)\n",
    "ax2.plot(rank_range, rmse_list, color=colory2)\n",
    "ax2.plot(rank_range, rmse_list_sub, color=colory2)\n",
    "ax2.tick_params(axis='y', labelcolor=colory2)\n",
    "\n",
    "ax1.grid(True)\n",
    "ax2.grid(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "(4) What does this relationship tell you about how much the data can be compressed using SVD?\n",
    "--> A higher RMSE means that more information is lost due to compressing the data using a SVD. By increasing the rank we can decrease the RMSE and therefore obtain more of the initial information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "(5) What is the physical interpretation of the U, Σ and V matrices from the SVD of the Tallinn SPL data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "U: Set of orthogonal basis vectors which capture spatial patterns in the sound pressure level across the different stations\n",
    "\n",
    "Σ: Contains singular values / importance of each basis vector (U) and capture the overall variation in the sound pressure levels. A larger singular value means indicates that the corresponding basis vector of U is more important\n",
    "\n",
    "V: Capture the temporal patterns of the SPL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}